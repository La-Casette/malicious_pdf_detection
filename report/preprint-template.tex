%% arara directives
% arara: xelatex
% arara: bibtex
% arara: xelatex
% arara: xelatex

%\documentclass{article} % One-column default
\RequirePackage[2020-02-02]{latexrelease}
\documentclass[twocolumn, switch]{article} % Method A for two-column formatting

\usepackage{preprint}

%% Math packages
\usepackage{amsmath, amsthm, amssymb, amsfonts}

%% Algorithm packages
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{caption}
% Images width
\newcommand\x{0.7}
%% Bibliography options
\usepackage[numbers,square]{natbib}
\bibliographystyle{unsrtnat}
%\usepackage{natbib}
%\bibliographystyle{Geology}

%% General packages
\usepackage[utf8]{inputenc}	% allow utf-8 input
\usepackage[T1]{fontenc}	% use 8-bit T1 fonts
\usepackage{xcolor}		% colors for hyperlinks
\usepackage{graphicx}
\graphicspath{{./assets/}}
\usepackage[colorlinks = true,
            linkcolor = purple,
            urlcolor  = blue,
            citecolor = black,
			allcolors = black,
            anchorcolor = black]{hyperref}	% Color links to references, figures, etc.
\usepackage{booktabs} 		% professional-quality tables
\usepackage{nicefrac}		% compact symbols for 1/2, etc.
\usepackage{microtype}		% microtypography
\usepackage{lineno}		% Line numbers
\usepackage{float}			% Allows for figures within multicol
%\usepackage{multicol}		% Multiple columns (Method B)

\usepackage{lipsum}		%  Filler text

 %% Special figure caption options
\usepackage{newfloat}
\DeclareFloatingEnvironment[name={Supplementary Fig.}]{suppfigure}
\usepackage{sidecap}
\sidecaptionvpos{figure}{c}

% Section title spacing  options
%\usepackage{titlesec}
%\titlespacing\section{0pt}{12pt plus 3pt minus 3pt}{1pt plus 1pt minus 1pt}
%\titlespacing\subsection{0pt}{10pt plus 3pt minus 3pt}{1pt plus 1pt minus 1pt}
%\titlespacing\subsubsection{0pt}{8pt plus 3pt minus 3pt}{1pt plus 1pt minus 1pt}
\usepackage[compact]{titlesec}
\titlespacing{\section}{0pt}{*0}{*0}
\titlespacing{\subsection}{0pt}{*0}{*0}
\titlespacing{\subsubsection}{0pt}{*0}{*0}

% ORCiD insertion
\usepackage{tikz,xcolor,hyperref}

\definecolor{lime}{HTML}{A6CE39}
\DeclareRobustCommand{\orcidicon}{
	\begin{tikzpicture}
	\draw[lime, fill=lime] (0,0) 
	circle [radius=0.16] 
	node[white] {{\fontfamily{qag}\selectfont \tiny ID}};
	\draw[white, fill=white] (-0.0625,0.095) 
	circle [radius=0.007];
	\end{tikzpicture}
	\hspace{-2mm}
}
\foreach \x in {A, ..., Z}{\expandafter\xdef\csname orcid\x\endcsname{\noexpand\href{https://orcid.org/\csname orcidauthor\x\endcsname}
			{\noexpand\orcidicon}}
}
% Define the ORCID iD command for each author separately. Here done for two authors.
\newcommand{\orcidauthorA}{0000-0000-0000-0001}
\newcommand{\orcidauthorB}{0000-0000-0000-0002}
\newcommand{\orcidauthorC}{0000-0000-0000-0003}
\newcommand{\orcidauthorD}{0000-0000-0000-0004}

%%%%%%%%%%%%%%%%   Title   %%%%%%%%%%%%%%%%
\title{Machine learning techniques for malicious pdf detection}

% Add watermark with submission status
\usepackage{xwatermark}
% Left watermark
% \newwatermark[firstpage,color=gray!60,angle=90,scale=0.32, xpos=-4.05in,ypos=0]{\href{https://doi.org/}{\color{gray}{Publication doi}}}
% Right watermark
% \newwatermark[firstpage,color=gray!60,angle=90,scale=0.32, xpos=3.9in,ypos=0]% {\href{https://doi.org/}{\color{gray}{Preprint doi}}}
% Bottom watermark
% \newwatermark[firstpage,color=gray!90,angle=0,scale=0.28, xpos=0in,ypos=-5in]% {*correspondence: \texttt{email@institution.edu}}
%%%%%%%%%%%%%%%  AUTHORS LIST  %%%%%%%%%%%%%%%
\usepackage{authblk}
\renewcommand*{\Authfont}{\bfseries}
\author{Mattia Rosso, Lorenzo Ippolito, Martino Picasso}


%%%%%%%%%%%%%%    Front matter    %%%%%%%%%%%%%%
\begin{document}

\twocolumn[ % Method A for two-column formatting
	\begin{@twocolumnfalse} % Method A for two-column formatting

		\maketitle
		%%%# ABSTRACT #%%
		\begin{abstract}
			This project presents an exhaustive analysis of machine learning techniques for detecting malicious PDF files. By comparing the performance of four binary classification models - Support Vector Machines (SVM), Decision Trees, Random Forests and K-Nearest Neighbors (KNN) - we demonstrate the effectiveness of these approaches in achieving high Accuracy and low False Negative Rates.
			What makes this project stand out is its focus on the machine learning models themselves, including the careful selection of hyperparameters to optimize their performance. Additionally, the inclusion of KNN as a valid model is rare in the field, and the analysis of evasion techniques adds another layer of depth to the study. Overall this paper, realized for the MALIS course at EURECOM (year 2022/2023), offers a comprehensive look at the use of machine learning for malicious PDF detection and the potential vulnerabilities of these models.
		\end{abstract}
		%\keywords{First keyword \and Second keyword \and More} % (optional)
		\vspace{0.35cm}

	\end{@twocolumnfalse} % Method A for two-column formatting
] % Method A for two-column formatting

%\begin{multicols}{2} % Method B for two-column formatting (doesn't play well with line numbers), comment out if using method A


%%%%%%%%%%%%%%%  Main text   %%%%%%%%%%%%%%%
% \linenumbers

%%%# INTRODUCTION #%%
\section{Introduction}
PDF (Portable Document Format) is a file format used for exchanging and sharing documents. It can contain various types of elements, such as text, images, multimedia, and executable code. Keywords, also known as actions or triggers, specify the different types of contents and they can be used to detect whether the file is malicious or benign. In addition, PDF files may include also fonts, annotations, and form fields, which can be exploited for malicious purposes. We implemented four different binary classifiers to analyze their performances and to prove which one achieves the best results in terms of Accuracy and False Negative Rate. The task is a binary classification, with malicious PDFs labelled as Positive and Benign PDFs labelled as Negative. We also investigated evasion techniques against our classifiers, concluding the work with the implementation of a countermeasure algorithm known as Adversarial Learning.


%%# RELATED WORK #%%
\section{Related work}
\label{sec:relatedwork}
We have adopted the Contagio dataset \cite{Contagio} as benchmark to train and test our models. It is one of the most considered data sources for many of the publications on the topic. Among the ones we have taken into account, Maiorca et al. \cite{maiorca_giacinto_corona_1970} extract data with PDFiD \cite{PDFiD} and use SVM and Random Forests,  Cuan et al. \cite{cuan_damien_delaplace_valois_2018} use PDFiD, train a RBF SVM and also explain how to perform evasion attacks and relative countermeasures. In \cite{li_liu_yan_yang_2022}, Li et al. explain the iterative Gradient Descent attack algorithm against RBF SVM.

%%# DATASETS AND FEATURES #%%
\section{Datasets and features}
\label{sec:datasetsandfeatures}
As first step in building our model, we needed to obtain a dataset of PDFs to use for training and evaluation and we adopted the Contagio dataset. It is a collection of malicious PDF files that has been widely used for research and testing purposes. The dataset contains $20209$ PDF samples ($11100$ Malicious and $9109$ Benign), including malware, phishing attacks and other types of malicious contents. The samples in the dataset are representative of the types of threats that are commonly encountered.\newline
We chose to perform a static analysis, which does not require opening the PDFs in a reader. Indeed, we used a tool called PDFiD to extract relevant information from the PDFs. PDFiD characterizes each PDF by extracting the number of occurrences of specific keywords. This allowed us to map each PDF into an array of 21 elements that became our features vector.\newline
Among the keywords that we selected, some are related to the structure of the PDF file, such as \textit{obj} and \textit{endobj}, which mark the beginning and end of an object, \textit{stream} and \textit{endstream}, which mark the beginning and end of a stream of data. We also included \textit{xref}, \textit{trailer}, and \textit{startxref}, which pertain to the organization of the file. Next, there are features related to the content of the PDF: we added \textit{/Page}, which specifies a page object in the file, and \textit{/Encrypt}. We also included \textit{/ObjStm}, which denotes an object stream, \textit{/JS} and \textit{/JavaScript}, which indicate the presence of JavaScript code. Additionally, we selected features related to actions that can be triggered by the PDF, such as \textit{/AA}, \textit{/OpenAction}, \textit{/XFA} and \textit{/AcroForm}, that could potentially exfiltrate information from users. We also included the features related to the types of data that may be present in the file, such as \textit{/JBIG2Decode}, \textit{/RichMedia}, \textit{/Launch} and \textit{/EmbeddedFile}. Finally we also chose \textit{/Colors}, which specifies the presence of more than 16 million colors.\newline
The output of PDFiD is then converted into a CSV file, which can be easily accessed using the \texttt{numpy} and \texttt{pandas} Python libraries. This CSV file serves as the basis for our data extraction pipeline, which we have implemented using the functions provided by PDFiD. It is important to note that the keywords we selected are well known to be discriminant for PDF malware analysis but they do not represent the full set that may appear in a PDF file.\newline
The plot in Fig. \ref{fig:parallel} shows that the features distribution is substantialy different between Benign and Malicious PDFs.

\begin{figure}[ht!]
	\centering
	\includegraphics[width=\x\linewidth]{data_extraction.png}
	\caption{Features extraction pipeline.}
	\label{fig:data}
	\vspace{-2mm}
\end{figure}

\begin{figure}[ht!]
	\centering
	\includegraphics[width=\x\linewidth]{parallel_coords.png}
	\caption{The parallel plot highlights the difference between the features of Benign PDFs (Blue) and Malicious PDFs (Red).}
	\label{fig:parallel}
	\vspace{-5mm}
\end{figure}

\subsection{Model Validation}
We statically split the dataset in Train and Test using a stratified approach supplied by the \texttt{sklearn} library \cite{scikit-learn}. The Training Set, which consists of 80\% of the samples, is used to train and validate the models with a k-fold cross-validation approach (that, using $k=5$, leads to an evaluation set of $16\%$ of the total samples). The Test Set, which consists of 20\% of the entire dataset, is used to make final considerations about the performance of the models trained with the best parameters/hyperparameters.
To evaluate our models, we used two metrics: the False Negative Rate (FNR) and the Accuracy defined as:
\begin{figure}[ht]
	\begin{align*}
		FNR = \frac{FN}{FN + TP} \quad Accuracy = \frac{TP+TN}{TP+TN+FP+FN}
	\end{align*}
	\caption*{\footnotesize{Where $FN$: Malicious predicted Benign, $FP$: Benign predicted Malicious, $TP$: Malicious predicted Malicious, $TN$: Benign predicted Benign.}}
\end{figure}
\\We aimed to minimize the FNR, as False Negatives (Malicious PDFs classified as Benign) can be particularly damaging in this context.
At the same time, we also took into consideration the value of the Accuracy, as the penalization of False Negative errors should not result in an excessively high number of False Positives that may lead to unnecessary alerts.

%%# SVM #%%
\section{Support vector machines}
\label{sec:svm}
% Intro that motivates why we use SVM (citing papers of \ref{sec:relatedwork})
Support Vector Machines are linear classifiers that look for maximum margin separation hyperplanes.
The soft margin SVM problem adds a penalty term $C\sum_{i=1}^{n}\xi_i$ to the hard margin SVM to relax the constraint of having points inside the margin. The hyperparameter $C$ is meant to define the strength of this penalization.
\subsection{Linear SVM}
% Few words about the linear SVM
We implemented a linear SVM classifier using the \texttt{sklearn} library \cite{scikit-learn}.

\subsubsection{Experiments}
% Results obtained with the linear SVM (plots)
We have cross-validated the linear model by trying $10$ different values for the $C$ hyperparameter in the range $[10^{-6}, 10]$. As explained in Section \ref{sec:datasetsandfeatures}, we optimized for the False Negative Rate (FNR) with the constraint of obtaining a high Accuracy anyway.

\begin{figure}[ht!]
	\centering
	\includegraphics[width=\x\linewidth]{linear_svm_accuracy_fnr.png}
	\caption{The plots show the change of the Accuracy (left) and the FNR (right) when the value of $C$ hyperparameter increases.}
	\label{fig:linearsvm}
\end{figure}

% comments on linear SVM
The plot in Fig. \ref{fig:linearsvm} shows that the variations in terms of Accuracy and FNR when different values of $C$ are used to train the linear SVM are not that evident. The results obtained with $C=10^{-6}$ are not reported here because of the significantly worse scores ($88.67\%$ of Accuracy and $2.94\%$ of FNR). 

\begin{table}[ht!]
	\centering
	{\small
		\begin{tabular}{|c|c|c|}
			\hline
			\textbf{C} & \textbf{Accuracy} & \textbf{FNR} \\ \hline
			2.22       & 99.06\%           & 1.38\%       \\ \hline
			6.67       & 99.03\%           & 1.35\%       \\ \hline
		\end{tabular}
	}
	\vspace{1mm}
	\caption{Best model parameters for Linear SVM.}
	\vspace{-6mm}
\end{table}

Optimizing for the FNR we have selected $C=6.67$.
\subsection{Kernel SVM}
% Why SVM are good: kernels
What makes the SVM particularly powerful is the way the dual problem is defined, since it allows to easily introduce a kernel function to express the problem in a higher dimensional features space. Thus, we implemented a Radial Basis Function (RBF) kernel defined as:
\begin{center}
	$k(x,y) = e^{-\gamma||x-y||^2}$
\end{center}

\subsubsection{Experiments}
\label{sub:expsvm}
% Results obtained with the RBF kernel SVM (plots)
The cross-validation of the model took into account two different hyperparameters ($\gamma$ of the RBF kernel and $C$ of the dual SVM problem).
This time we exploited a grid search k-fold cross-validation that trains the model with each possible combinations of hyperparameters. The values we tried are:
\begin{itemize}
	\item $\gamma$: 10 values in $[10^{-6}, 1]$
	\item $C$: 10 values in $[10^{-6}, 10]$
\end{itemize}
We investigated the influence of both hyperparameters. What it is not displayed and analyzed in the plots is what happens with $C=10^{-6}$ and $\gamma=10^{-6}$, values under which the classifier performs very poorly in terms of Accuracy (around $54\%$) despite achieving a $FNR$ equal to $0\%$. However, this is not better than a dummy classifier that safely detects every PDF as Malicious, hence it is not of interest in this project.

\begin{figure}[ht!]
	\centering
	\includegraphics[width=\x\linewidth]{rbf_svm_gamma_accuracy_fnr.png}
	\caption{Accuracy (top) and FNR (bottom) when $\gamma$ (colored lines) and $C$ changes.}
	\label{fig:rbfsvmgamma}
\end{figure}

From Fig. \ref{fig:rbfsvmgamma} it is clear that smaller values of $\gamma$ lead to obtain better results both in terms of Accuracy and FNR. The $\gamma$ parameter of the RBF kernel controls its width and the shape of the decision boundary. A lower value of gamma means a larger, less concentrated kernel, which can lead to smoother decision boundaries.\newline
In contrast, the value of the $C$ hyperparameter has clearly less influence on the model than $\gamma$, as we can observe in Fig. \ref{fig:rbfsvmgamma}. It controls the trade-off between the simplicity of the model (low bias, high variance) and the training error (low variance, high bias). A higher value of $C$ means a higher penalty for misclassification.
When $\gamma$ is sufficiently small, the Accuracy reaches the best values and the same happens for the FNR.
Overall the best values we have found from cross-validation are:
\begin{center}
	$C=5.56\quad\gamma=0.11 \quad Accuracy=99.50\% \quad FNR=0.82\%$
\end{center}

\subsection{Performances on Test Set}
Finally, given the best hyperparameters found in Section \ref{sub:expsvm}, we assessed the performances achieved on the Test Set.
\subsubsection{Linear SVM}
The obtained results are:
\begin{center}
	$C=6.67 \quad Accuracy=99.06\% \quad FNR=1.58\%$
\end{center}
The scores obtained are comparable with the ones achieved on the Training Set. Despite a smaller improvement in the Accuracy, a slightly worse FNR has been obtained.

\subsubsection{Kernel SVM}
The RBF SVM on the entire Test Set achieves these results:
\begin{center}
	$C=5.56 \quad \gamma=0.11 \quad Accuracy=99.73\% \quad FNR=0.36\%$
\end{center}
Here, in constrast with the linear model, we obtained better results both in terms of Accuracy and FNR.
%%# DECISION TREE AND RANDOM FOREST #%%
\section{Decision Trees and Random Forests}
\label{sec:tree}
\subsection{Decision Trees}
The Decision Trees is a classification technique in which predictions are made in a sequence of single-attribute tests.
Each internal node represents a test on an attribute and each branch represents the outcome of the test. The paths from the root to the leaf nodes represent the classification rules, and the leaf nodes represent the class labels.
\subsubsection{Experiments}
\label{sub:tree}
We performed a k-fold cross-validation with 5 folds in order to learn the best model parameters on the Training Set with more focus on $max\_depth$. The results are shown in Fig. \ref{fig:treetrain} and summarized in Tab. \ref{tab:treetrain}.
\begin{figure}[ht!]
	\centering
	\includegraphics[width=\x\linewidth]{tree_accuracy_fnr.png}
	\caption{Accuracy (left) and FNR (right) when $max\_depth$ changes.}
	\label{fig:treetrain}
\end{figure}

\begin{table}[ht!]
	\centering
	{\small
		\begin{tabular}{|c|c|c|c|}
			\hline
			\textbf{max\_depth} & \textbf{Accuracy} & \textbf{FNR} \\ \hline
			15                 & 99.72\%           & 0.21\%       \\ \hline
			9                  & 99.74\%           & 0.28\%       \\ \hline
		\end{tabular}
		\vspace{1mm}
		\caption{Decision Trees - Optimal depths from cross-validation.}
		\label{tab:treetrain}
		\vspace{-5mm}
	}
\end{table}
Despite the model achieves the best Accuracy with $max\_depth = 9$, we chose $max\_depth = 15$ that achieves the lowest $FNR$.

\subsection{Random Forests}
Random Forests is an ensemble method that combines the predictions of multiple Decision Trees models to make more accurate and stable predictions.
To train a Random Forests model, multiple Decision Trees are trained on different samples of the data and their predictions are combined. This helps to reduce overfitting and improve the model's generalization ability.

\subsubsection{Experiments}
\label{sub:randomforest}
We performed a k-fold cross-validation with 5 folds in order to learn the best model parameters on the Training Set with more focus on $max\_depth$. The plot in Fig. \ref{fig:foresttrain} shows how both the Accuracy and the FNR improve as the depth increases. Choosing a not too high value of depth is crucial to avoid overfitting.

\begin{figure}[ht!]
	\centering
	\includegraphics[width=\x\linewidth]{randomforest_accuracy_fnr.png}
	\caption{Accuracy (left) and FNR (right) when $max\_depth$ increases.}
	\label{fig:foresttrain}
\end{figure}
The best obtained result is:
\begin{center}
	$max\_depth=16 \quad Accuracy=99.80\% \quad FNR=0.22\%$
\end{center}

\subsection{Performances on Test Set}
The results obtained on the Test Set of both Decision Trees and Random Forests using the best model parameters discussed in \ref{sub:tree} and \ref{sub:randomforest} are:
\begin{center}
	\textbf{Decision Trees}\\
	$max\_depth=15 \quad Accuracy=99.75\% \quad FNR=0.22\%$\\~\\
	\textbf{Random Forests}\\
	$max\_depth=16 \quad Accuracy=99.90\% \quad FNR=0.13\%$
\end{center}

%%# KNN #%%
\section{K-Nearest Neighbors}
\label{sec:knn}
K-Nearest Neighbors (KNN) works by identifying the $K$ number of training samples that are closest in distance to the input sample and then assigning the input sample to the class of the majority of the $K$ nearest neighbors. We implemented it with \texttt{sklearn} \cite{scikit-learn} using the default Euclidean distance.
\subsection{Experiments}
We performed a k-fold cross-validation with 5 folds.
To determine the optimal value of $K$ (the number of nearest neighbors to consider), we conducted a grid search over a range of possible values ($K \in [1, 8]$).
\begin{figure}[ht!]
	\centering
	\includegraphics[width=\x\linewidth]{knn_accuracy_fnr.png}
	\caption{Accuracy (left) and FNR (right) when $K$ increases.}
	\label{fig:knntrain}
\end{figure}
The results of this search shows, as expected, that the best performances are achieved with $K=1$. Since we have selected very discriminant features and we dispose of a large and diverse dataset, we expect that the possible overfitting effect is not really high.
To visualize the effect of increasing $K$ on the performance of our model, we plotted in Fig. \ref{fig:knntrain} the Accuracy and FNR as a function of $K$. The performance of the model slightly decreases as $K$ increases. This is to be expected, as increasing $K$ allows the model to consider more neighbors, which can introduce more noise and reduce the model's ability to accurately classify samples. The best result obtained is:
\begin{center}
	$K=1 \quad Accuracy=99.67\% \quad FNR=0.82\%$
\end{center}

\subsection{Performances on Test Set}
The results on the Test Set are:
\begin{center}
	$K=1 \quad Accuracy=99.68\% \quad FNR=0.36\%$
\end{center}

We also obtained excellent results on the Test Set. We could explain the fact that $K=1$ is still the best model parameter by noticing that, despite the dataset is made of PDFs that are unique, PDFiD is able to extract such discriminant features that different PDFs result to be equal in terms of the extracted features vector. Having overlapped samples in the features space is really helpful for the way KNN classifies because the nearest neighbor of a test sample will probably consist in different overlapped samples, most of them belonging to the same class.
Our results demonstrate that KNN is an effective technique for detecting Malicious PDFs and that it can achieve high level performances with relatively little tuning.

%%# FINAL RESULTS #%%
\section{Final results}
\label{sec:finalresults}
We have summarized the results of all our classifiers in Tab. \ref{tab:finalresults}.
The table shows that, as widely discussed in the previous sections, the model that achieves the best results is the Random Forests. Actually, all of them reach an impressively high Accuracy and low FNR. This is also coherent with the results obtained in Maiorca et al. \cite{maiorca_giacinto_corona_1970} that proved Random Forests to be the best performing model.
\begin{table}[ht!]
	\centering
	{\small
		\begin{tabular}{|c|cc|cc|}
			\hline
			                                                                        & \multicolumn{2}{c|}{\textit{\textbf{Train}}} & \multicolumn{2}{c|}{\textit{\textbf{Test}}}                                                         \\ \hline
			\textbf{Model}                                                          & \multicolumn{1}{c|}{\textbf{Accuracy}}       & \textbf{FNR}                                & \multicolumn{1}{c|}{\textbf{Accuracy}} & \textbf{FNR} \\ \hline
			\begin{tabular}[c]{@{}c@{}}Tree\\ $depth=15$\end{tabular}               & \multicolumn{1}{c|}{99.72\%}                 & 0.21\%                                      & \multicolumn{1}{c|}{99.75\%}           & 0.22\%       \\ \hline
			\begin{tabular}[c]{@{}c@{}}Forest\\ $depth=16$\end{tabular}             & \multicolumn{1}{c|}{99.80\%}                 & 0.22\%                                      & \multicolumn{1}{c|}{99.90\%}           & 0.13\%       \\ \hline
			\begin{tabular}[c]{@{}c@{}}KNN\\ $k=1$\end{tabular}                     & \multicolumn{1}{c|}{99.67\%}                 & 0.82\%                                      & \multicolumn{1}{c|}{99.68\%}           & 0.36\%       \\ \hline
			\begin{tabular}[c]{@{}c@{}}LSVM\\ $C=6.67$\end{tabular}                 & \multicolumn{1}{c|}{99.03\%}                 & 1.35\%                                      & \multicolumn{1}{c|}{99.06\%}           & 1.58\%       \\ \hline
			\begin{tabular}[c]{@{}c@{}}KSVM\\ $C=5.56$\\ $\gamma=0.11$\end{tabular} & \multicolumn{1}{c|}{99.50\%}                 & 0.82\%                                      & \multicolumn{1}{c|}{99.73\%}           & 0.36\%       \\ \hline
		\end{tabular}
		\vspace{1mm}
		\caption{Overall results of all the models (LSVM: linear SVM, KSVM: RBF Kernel SVM). Results on Training Set are the ones obtained through k-fold cross-validation.}
		\label{tab:finalresults}
	}
	\vspace{-5mm}
\end{table}

Finally we also plotted the ROC curves for all the models. In Fig. \ref{fig:roc} we can  confirm the results showed in Tab. \ref{tab:finalresults}.
\begin{figure}[ht!]
	\centering
	\includegraphics[width=\x\linewidth]{roc.png}
	\caption{ROC curves comparing all the models. }
	\label{fig:roc}
\end{figure}

%%# ATTACKS TO CLASSIFIERS #%%
\section{Attacking the classifiers}
\label{sec:attacks}
In this Section, we present two evasion attacks against the classifiers we built and a countermeasure. We increased the number of objects in Malicious PDFs so that they will be detected as Benign by the classifiers (still preserving their malicious behaviour). We operated in a condition in which the attacker is equipped with the Training Set, the type of classifier and the model parameters used to train it.
\subsection{Attack against SVM}
\label{subsec:svm}
We have studied an evasion attack based on the Gradient Descent algorithm following the idea of Cuan et al. in \cite{cuan_damien_delaplace_valois_2018}. Given
a features vector $x$ characterizing a Malicious PDF correctly classified, our goal is to find a $x'$ that will be detected as Benign. The constraint is that $x'$ is obtained with a minimal perturbation over $x$. The function to be minimized is the L1 distance between $x'$ and $x$:
\begin{center}
	$||x-x'||_1 = \sum_{i=1}^{d}x_i-x_i'$
\end{center}

The Gradient Descent attack converges to the minimum iteratively. Following the approach of Li et al. in \cite{li_liu_yan_yang_2022}, the feature vector is moved in the negative direction of the normal to the decision boundary, meaning that the Gradient Descent update step becomes:

\begin{center}
	$x_{t+1} = x_t - \mu_t\nabla_xf_{\Phi}(x_t)$
\end{center}
By recovering that $w = \nabla_x(w^Tx_t+w_0)$ for a linear SVM it can be derived that $w = \nabla_xf_{\Phi}(x_t)$ in a kernel SVM.
We obtained the expression for a RBF kernel SVM from the dual problem definition:
\begin{center}
	$\nabla_xf_{\Phi}(x_t) = \sum_{i \in SV}^{}\alpha_iz_i\nabla_xk(x_i,x_t)$
	where $\nabla_xk(x_i,x_t) = \nabla_{x_t}e^{-\gamma||x_i-x_t||^2}=-2\gamma\alpha_i z_i(x_i - x_t)e^{-\gamma||x_i-x_t||^2}$
\end{center}
To better get the idea behind the attack, we trained a RBF SVM ($C=1$, $\gamma=0.1$) on the dataset preprocessing it with PCA (with 2 components) just to visualize it. In Fig. \ref{fig:svmattack} a random Malicious PDF is perturbated iteratively (using a learning rate for the Gradient Descent of $\mu=0.03$) and it is successfully attacked.
\begin{figure}[ht!]
	\centering
	\includegraphics[width=\x\linewidth]{svmattack.png}
	\caption{Decision boundary of RBF SVM ($C=1$, $\gamma=0.1$) on $PCA=2$ dataset (left), Gradient Descent attack on a random Malicious PDF (right). (Blue: Benign, Red: Malicious).}
	\label{fig:svmattack}
\end{figure}
We only inspected the working mechanism of this evasion attack by trying to successfully craft Benign PDFs from malicious ones.

\subsection{Attack against Decision Trees}
\label{subsec:tree}
We also investigated an attack against the Decision Trees classifier. Firstly we found a new way to craft Malicious PDFs that are detected as Benign, using the approach explained in the Pseudocode \ref{alg:evasion}.
\begin{algorithm}
	{\footnotesize
		\caption{Evasion Attack}\label{alg:evasion}
		\begin{algorithmic}
			\Require Train DecisionTree using $X_{train}$
			\State $M \gets X_{train}[malicious]$
			\State $t \gets 50$
			\For{$m_i \in M$}
			\For{$feature_j \in m_i$}
			\While{$feature_j < t$}
			\State $feature_j \gets feature_j + 1$
			\State $m_i[j] \gets feature_j$
			\State $Benign \gets predict(m_i)$
			\If{$Benign$ is $True$}
			\State $break$  \Comment{PDF evaded}
			\EndIf
			\EndWhile
			\EndFor
			\Comment{PDF not evaded}
			\EndFor
		\end{algorithmic}
	}
\end{algorithm}

With a threshold $t=50$ we obtained a success rate of evasion attack on the Training Set equal to $91.28\%$.

\subsection{Adversarial Learning}
In order to improve the strenght of the Decision Trees classifier against the attack procedure in \ref{subsec:tree}, we implemented a defense mechanism similar to what has been implemented by Cuan et al. in \cite{cuan_damien_delaplace_valois_2018}.
It is called Adversarial Learning and the algorithm is shown in Pseudocode \ref{alg:advlearn}.

\begin{algorithm}
	{\footnotesize
		\caption{Adversarial Learning}\label{alg:advlearn}
		\begin{algorithmic}
			\Require Train DecisionTree using $X_{train}$
			\State $t \gets 50$
			\State $X_{train}^{imp} \gets X_{train}$
			\State $M \gets X_{train}[malicious]$
			\While{$\#PDF evaded > 0$}
			\State $evaded,X_{train}^{evaded} \gets evade(M,t)$
			\If{$evaded$ is $True$}
			\State $X_{train}^{imp} \gets X_{train}^{imp} + X_{train}^{evaded}$
			\EndIf
			\State $train(X_{train}^{imp})$
			\EndWhile
		\end{algorithmic}
	}
\end{algorithm}

The results we obtained are overall satisfying because the classifier is able to defend perfectly against our evasion algorithm.

\begin{figure}[ht!]
	\centering
	\includegraphics[width=\x\linewidth]{adv_learning.png}
	\caption{Adversarial Learning defense effectivness in different iterations: although the different spikes, the number of evadable PDFs of Training Set reduces progressively and reaches $0$.}
	\label{fig:advlearn}
\end{figure}
The plot in Fig. \ref{fig:advlearn} shows that the number of PDFs that can be evaded in the Training Set reaches $0$ at iteration $69$.\\
We can also see in Fig. \ref{fig:improved} how the features of the improved dataset (the ones obtained adding the crafted PDFs to the original Training Dataset) have been modified to defend against this attack.

\begin{figure}[ht!]
	\centering
	\includegraphics[width=\x\linewidth]{hist_train_improved.png}
	\caption{Difference of features frequencies between $X_{train}$ and $X_{train}^{imp}$ (logarithmic scale).}
	\label{fig:improved}
\end{figure}
%%# CONCLUSIONS #%%
\section{Conclusions and future works}
\label{sec:conclusions}
\paragraph{Classifiers}
To conclude, the model that performs better is the Random Forests, both in terms of Accuracy and FNR. Comparable results are achieved by the other models and the use of PDFiD makes all the algorithms efficient in detecting patterns using the most discriminant features. Further improvements could be done in order to achieve even lower values of FNR. Dimensionality reduction techniques could be exploited toghether with other types of metrics that take into account both the Accuracy and the FNR.
\vspace{-10pt}
\paragraph{Evasion Attacks}
The evasion attack against the Decision Trees showed a really high success rate on the Training Set. We thus implemented the defense mechanism that proved to be very effective using Adversarial Learning. We could investigate more the size of the improved training dataset needed to mitigate the attack.

%%# CONTRIBUTIONS #%%
\section{Contributions}
\label{sec:contributions}
These are the contributions of each member:
\begin{itemize}
	\item M. Rosso worked on SVM classifiers investigating the role of the different hyperparameters and the formulation of the dual soft margin SVM problem to be used in the evasion attacks.
	\item L. Ippolito worked on Decision Trees and Random Forests classifiers carefully exploring all the model parameters and the presence of overfitting.
	\item M. Picasso studied the KNN classifier to better understand the reason why $K=1$ is the best performing parameter.
\end{itemize}
We collaborated as a team both in the features extraction phase and on the choice of the model validation approach. After having assessed the performances of all the models, we worked toghether on designing the evasion attacks algorithms and the countermeasures.
\\~\\
The project directory can be found at:\newline
\footnotesize{\url{https://github.com/La-Casette/malicious_pdf_detection}}
%%%%%%%%%%%% Supplementary Methods %%%%%%%%%%%%
%\footnotesize
%\section*{Methods}

%%%%%%%%%%%%% Acknowledgements %%%%%%%%%%%%%
%\footnotesize
%\section*{Acknowledgements}

%%%%%%%%%%%%%%   Bibliography   %%%%%%%%%%%%%%
\normalsize
\bibliography{references}

%%%%%%%%%%%%  Supplementary Figures  %%%%%%%%%%%%
%\clearpage

%%%%%%%%%%%%%%%%   End   %%%%%%%%%%%%%%%%
%\end{multicols}  % Method B for two-column formatting (doesn't play well with line numbers), comment out if using method A
\end{document}
